<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8" />
    <title>Autobiography STT + SSE í…ŒìŠ¤íŠ¸ (VAD ì ìš©)</title>
    <style>
        body { font-family: sans-serif; max-width: 700px; margin: 2rem auto; }
        #messages { border: 1px solid #ccc; padding: 1rem; height: 300px; overflow-y: auto; }
        .ai    { text-align: left;  color: #090; }
        .user  { text-align: right; color: #006; }
        .error { text-align: left; color: #f66; }
        .system { text-align: center; color: #888; font-style: italic; }
        button, input { padding: .5rem; margin: .5rem 0; width: 100%; box-sizing: border-box; }

        #audioLevel {
            width: 100%;
            height: 20px;
            background: #f0f0f0;
            border-radius: 10px;
            overflow: hidden;
            margin: 10px 0;
        }

        #audioLevelBar {
            height: 100%;
            background: linear-gradient(90deg, #4CAF50, #FFC107, #FF5722);
            width: 0%;
            transition: width 0.1s ease;
        }

        .settings {
            background: #f9f9f9;
            padding: 1rem;
            border-radius: 5px;
            margin: 1rem 0;
        }

        .settings label {
            display: block;
            margin: 0.5rem 0;
        }
    </style>
    <script src="https://cdn.jsdelivr.net/npm/axios/dist/axios.min.js"></script>
</head>
<body>
<h2>Autobiography STT + SSE í…ŒìŠ¤íŠ¸ (VAD ì ìš©)</h2>
<div id="messages"></div>

<div class="settings">
    <label>
        <input type="checkbox" id="enableVAD" checked /> VAD (ìŒì„± í™œë™ ê°ì§€) ì‚¬ìš©
    </label>
    <label>
        ìŒì„± ê°ì§€ ì„ê³„ê°’: <span id="thresholdValue">0.01</span>
        <input type="range" id="threshold" min="0.001" max="0.1" step="0.001" value="0.01" />
    </label>
    <label>
        ë¬´ìŒ í—ˆìš© ì‹œê°„ (ì´ˆ): <span id="silenceTimeValue">10</span>
        <input type="range" id="silenceTime" min="1" max="30" step="1" value="10" />
    </label>
</div>

<div id="audioLevel">
    <div id="audioLevelBar"></div>
</div>

<input type="text" id="properInput" placeholder="ê³ ìœ ëª…ì‚¬ë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•´ ì…ë ¥í•˜ì„¸ìš”" />
<button id="startBtn">â–¶ ì—í”¼ì†Œë“œ ì‹œì‘</button>
<button id="recordBtn" disabled>ğŸ™ï¸ ë…¹ìŒ ì‹œì‘</button>
<button id="stopBtn" disabled>â¹ï¸ ë…¹ìŒ ì¤‘ì§€</button>

<script>
    const msgs        = document.getElementById('messages');
    const properInput = document.getElementById('properInput');
    const startBtn    = document.getElementById('startBtn');
    const recordBtn   = document.getElementById('recordBtn');
    const stopBtn     = document.getElementById('stopBtn');
    const enableVAD   = document.getElementById('enableVAD');
    const threshold   = document.getElementById('threshold');
    const thresholdValue = document.getElementById('thresholdValue');
    const silenceTime = document.getElementById('silenceTime');
    const silenceTimeValue = document.getElementById('silenceTimeValue');
    const audioLevelBar = document.getElementById('audioLevelBar');

    let sessionId   = crypto.randomUUID();
    let episodeId   = 1;
    let chunkIndex  = 0;
    let source, mediaRecorder, stream, chunkTimer, audioContext, analyser;
    let isRecording = false;
    let currentAudioLevel = 0;
    let lastSpeechTime = 0;
    let voiceDetected = false;

    // ì„¤ì •ê°’ ì—…ë°ì´íŠ¸
    threshold.oninput = () => {
        thresholdValue.textContent = threshold.value;
    };

    silenceTime.oninput = () => {
        silenceTimeValue.textContent = silenceTime.value;
    };

    function append(txt, cls='ai') {
        const d = document.createElement('div');
        d.className = cls;
        d.textContent = txt;
        msgs.appendChild(d);
        msgs.scrollTop = msgs.scrollHeight;
    }

    // ì˜¤ë””ì˜¤ ë ˆë²¨ ë¶„ì„ í•¨ìˆ˜
    function analyzeAudio() {
        if (!analyser) return;

        const bufferLength = analyser.frequencyBinCount;
        const dataArray = new Uint8Array(bufferLength);
        analyser.getByteFrequencyData(dataArray);

        // RMS (Root Mean Square) ê³„ì‚°
        let sum = 0;
        for (let i = 0; i < bufferLength; i++) {
            sum += dataArray[i] * dataArray[i];
        }
        const rms = Math.sqrt(sum / bufferLength);
        currentAudioLevel = rms / 255; // 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”

        // ì˜¤ë””ì˜¤ ë ˆë²¨ ë°” ì—…ë°ì´íŠ¸
        audioLevelBar.style.width = (currentAudioLevel * 100) + '%';

        // ìŒì„± ê°ì§€ ë¡œì§
        const currentThreshold = parseFloat(threshold.value);
        const currentSilenceTime = parseFloat(silenceTime.value) * 1000; // msë¡œ ë³€í™˜

        if (currentAudioLevel > currentThreshold) {
            lastSpeechTime = Date.now();
            if (!voiceDetected) {
                voiceDetected = true;
                append('ğŸ¤ ìŒì„± ê°ì§€ë¨', 'system');
            }
        } else if (voiceDetected && Date.now() - lastSpeechTime > currentSilenceTime) {
            voiceDetected = false;
            append('ğŸ”‡ ìŒì„± ì¤‘ë‹¨ ê°ì§€', 'system');
        }

        if (isRecording) {
            requestAnimationFrame(analyzeAudio);
        }
    }

    startBtn.onclick = () => {
        source = new EventSource(
            `http://localhost:8080/api/stream/questions?sessionId=${sessionId}&episodeId=${episodeId}`
        );
        // 1) AI ì§ˆë¬¸
        source.addEventListener('question', e => {
            const { text } = JSON.parse(e.data);
            append(`AI: ${text}`, 'ai');
            recordBtn.disabled = false;
        });
        // 2) ì¤‘ê°„ STT
        source.addEventListener('partialTranscript', e => {
            const { chunkIndex, text } = JSON.parse(e.data);
            append(`(${chunkIndex}) ìŒì„± ì¸ì‹ ì¤‘â€¦ ${text}`, 'user');
        });
        // 3) ìµœì¢… STT
        source.addEventListener('finalTranscript', e => {
            const { chunkIndex, text } = JSON.parse(e.data);
            append(`âœ… ìµœì¢… ì¸ì‹ (#${chunkIndex}): ${text}`, 'user');
        });
        source.addEventListener('error', () => {
            append('âŒ SSE ì—ëŸ¬', 'error');
            source.close();
        });

        append(`ì„¸ì…˜ ì—´ë¦¼: ${sessionId}`, 'user');
        startBtn.disabled = true;
    };

    recordBtn.onclick = async () => {
        try {
            stream = await navigator.mediaDevices.getUserMedia({ audio: true });

            // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì„¤ì •
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const source = audioContext.createMediaStreamSource(stream);
            analyser = audioContext.createAnalyser();
            analyser.fftSize = 2048;
            source.connect(analyser);

            isRecording = true;
            voiceDetected = false;
            lastSpeechTime = Date.now();

            startChunkRecorder();
            analyzeAudio(); // ì˜¤ë””ì˜¤ ë¶„ì„ ì‹œì‘

            append('ğŸ™ï¸ ë…¹ìŒ ì‹œì‘ (ìŒì„± í™œë™ ê°ì§€ ëª¨ë“œ)', 'user');
            recordBtn.disabled = true;
            stopBtn.disabled   = false;
        } catch (err) {
            append('âŒ ë§ˆì´í¬ ì ‘ê·¼ ì˜¤ë¥˜: ' + err.message, 'error');
        }
    };

    stopBtn.onclick = () => {
        isRecording = false;
        voiceDetected = false;
        clearTimeout(chunkTimer);

        if (mediaRecorder && mediaRecorder.state !== 'inactive') {
            mediaRecorder.stop();
        }

        if (stream) {
            stream.getTracks().forEach(t => t.stop());
        }

        if (audioContext) {
            audioContext.close();
            audioContext = null;
            analyser = null;
        }

        // ì˜¤ë””ì˜¤ ë ˆë²¨ ë°” ì´ˆê¸°í™”
        audioLevelBar.style.width = '0%';

        append('ğŸ”Š ë…¹ìŒ ì™„ì „ ì¢…ë£Œ', 'user');
        stopBtn.disabled   = true;
        recordBtn.disabled = false;
    };

    // ê°œì„ ëœ ì²­í¬ ë ˆì½”ë” (VAD ì ìš©)
    function startChunkRecorder() {
        mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm;codecs=opus' });

        mediaRecorder.ondataavailable = async e => {
            if (!e.data || e.data.size === 0) return;

            // VADê°€ í™œì„±í™”ëœ ê²½ìš°ì—ë§Œ ìŒì„± ì²´í¬
            if (e.data.size < 1000) {
                append(`ğŸ§¹ ë¬´ìŒ ì²­í¬ ë¬´ì‹œë¨ (size=${e.data.size})`, 'system');
                chunkIndex++;
                return;
            }
            const form = new FormData();
            form.append('sessionId', sessionId);
            form.append('chunkIndex', chunkIndex++);
            form.append('audio', e.data, 'audio.webm');
            form.append('finalTranscript', 'false');
            form.append('audioLevel', currentAudioLevel.toFixed(3)); // ì˜¤ë””ì˜¤ ë ˆë²¨ ì •ë³´ ì¶”ê°€

            const cpns = properInput.value.trim();
            if (cpns) form.append('customProperNouns', cpns);

            try {
                const statusMsg = enableVAD.checked ?
                    `ğŸ“¤ ì²­í¬ #${chunkIndex-1} ì „ì†¡ ì¤‘... (ë ˆë²¨: ${(currentAudioLevel*100).toFixed(1)}%)` :
                    `ğŸ“¤ ì²­í¬ #${chunkIndex-1} ì „ì†¡ ì¤‘... (VAD ë¹„í™œì„±í™”)`;
                append(statusMsg, 'system');
                await axios.post('http://localhost:8080/api/stt/chunk', form, { timeout: 60000 });
            } catch (err) {
                append('âŒ STT ì˜¤ë¥˜: ' + (err.response?.data?.message || err.message), 'error');
            }
        };

        mediaRecorder.onstop = () => {
            if (isRecording) {
                // ë‹¤ìŒ ì²­í¬ ë…¹ìŒì„ ë°”ë¡œ ì‹œì‘
                startChunkRecorder();
            }
        };

        mediaRecorder.start();

        // 3ì´ˆ ë’¤ì— stop() í˜¸ì¶œ
        chunkTimer = setTimeout(() => {
            if (mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
            }
        }, 6000);
    }
</script>
</body>
</html>